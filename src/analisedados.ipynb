{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import levene\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "treino = pd.read_csv('train.csv') \n",
    "\n",
    "treino.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = treino.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = treino.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "missing_values = treino.isnull().sum()\n",
    "missing_percentage = (missing_values / len(treino)) * 100\n",
    "\n",
    "print(\"Variáveis Numéricas:\\n\")\n",
    "for col in num_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nVariáveis Categóricas:\\n\")\n",
    "for col in cat_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nValores Faltantes:\\n\")\n",
    "for col, val in missing_values[missing_values > 0].items():\n",
    "    print(f\"  - {col}: {val} valores faltantes ({missing_percentage[col]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de colunas categóricas que precisam ser codificadas\n",
    "categorical_cols = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', \n",
    "                    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', \n",
    "                    'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n",
    "                    'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \n",
    "                    'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', \n",
    "                    'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                    'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', \n",
    "                    'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', \n",
    "                    'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', \n",
    "                    'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', \n",
    "                    'SaleType', 'SaleCondition']\n",
    "\n",
    "for column in categorical_cols:\n",
    "    print(column)\n",
    "    print(treino[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = OrdinalEncoder()\n",
    "for column in categorical_cols:\n",
    "    treino[f\"{column}_le\"] = le.fit_transform(treino[column].values.reshape(-1, 1))\n",
    "\n",
    "for column in categorical_cols:\n",
    "    print(column)\n",
    "    print(treino[column].unique())\n",
    "    print(treino[f\"{column}_le\"].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = treino.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = treino.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "missing_values = treino.isnull().sum()\n",
    "missing_percentage = (missing_values / len(treino)) * 100\n",
    "\n",
    "print(\"Variáveis Numéricas:\\n\")\n",
    "for col in num_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nVariáveis Categóricas:\\n\")\n",
    "for col in cat_cols:\n",
    "    print(f\"  - {col}\")\n",
    "\n",
    "print(\"\\nValores Faltantes:\\n\")\n",
    "for col, val in missing_values[missing_values > 0].items():\n",
    "    print(f\"  - {col}: {val} valores faltantes ({missing_percentage[col]:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização de variáveis numéricas\n",
    "scaler = StandardScaler()\n",
    "treino[num_cols] = scaler.fit_transform(treino[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preenchendo dados ausentes na coluna LotFrontage com a mediana\n",
    "treino['LotFrontage'].fillna(treino['LotFrontage'].median(), inplace=True)\n",
    "# Preenchendo dados ausentes na coluna Alley com \"None\"\n",
    "treino['Alley'].fillna('None', inplace=True)\n",
    "# Preenchendo dados ausentes na coluna PoolQC com \"None\"\n",
    "treino['PoolQC'].fillna('None', inplace=True)\n",
    "# Preenchendo dados ausentes na coluna Fence com \"None\"\n",
    "treino['Fence'].fillna('None', inplace=True)\n",
    "# Preenchendo dados ausentes na coluna MiscFeature com \"None\"\n",
    "treino['MiscFeature'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionando features e target\n",
    "features = treino.columns.tolist()\n",
    "target = 'SalePrice'\n",
    "\n",
    "X = treino[features]\n",
    "y = treino[target]\n",
    "\n",
    "# Codificando variáveis categóricas\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Separando variáveis numéricas e categóricas\n",
    "categorical_cols = [cname for cname in X.columns if X[cname].dtype == \"object\"]\n",
    "numerical_cols = [cname for cname in X.columns if X[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(treino.describe())\n",
    "\n",
    "num_cols = treino.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_cols = treino.select_dtypes(include=[object]).columns.tolist()\n",
    "\n",
    "missing_values = treino.isnull().sum()\n",
    "missing_percentage = (missing_values / len(treino)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de nova feature (ÁREA TOTAL DA CASA)\n",
    "treino['TotalSF'] = treino['TotalBsmtSF'] + treino['1stFlrSF'] + treino['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 30))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(10, 4, i + 1)\n",
    "    sns.histplot(treino[col], kde=True, bins=30, color='blue')\n",
    "    plt.title(col)\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "summary_numeric = {}\n",
    "for col in num_cols:\n",
    "    summary_numeric[col] = treino[col].describe()\n",
    "\n",
    "for col, stats in summary_numeric.items():\n",
    "    print(f\"\\nEstatísticas para coluna '{col}':\\n{stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cat_cols = len(cat_cols)\n",
    "num_rows = (num_cat_cols // 2) + (num_cat_cols % 2)\n",
    "plt.figure(figsize=(20, num_rows * 6))\n",
    "\n",
    "for i, col in enumerate(cat_cols, 1):\n",
    "    plt.subplot(num_rows, 2, i)\n",
    "    sns.histplot(x=col, data=treino, color='blue')\n",
    "    plt.title(f'Distribuição de {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "summary_categorical = {}\n",
    "for col in cat_cols:\n",
    "    summary_categorical[col] = treino[col].describe()\n",
    "\n",
    "for col, stats in summary_categorical.items():\n",
    "    print(f\"\\nEstatísticas para coluna '{col}':\\n{stats}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = treino[num_cols].corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "top_correlations = correlations.head(11)\n",
    "print(\"Top 10 correlações com SalePrice:\\n\", top_correlations)\n",
    "\n",
    "bottom_correlations = correlations.tail(10)\n",
    "print(\"\\nBottom 10 correlações com SalePrice:\\n\", bottom_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_results = []\n",
    "\n",
    "for col in cat_cols:\n",
    "    categories = treino[col].unique()\n",
    "    \n",
    "    if all(treino[treino[col] == category]['SalePrice'].count() > 1 for category in categories):\n",
    "        try:\n",
    "            anova = f_oneway(*[treino[treino[col] == category]['SalePrice'] for category in categories])\n",
    "            anova_results.append((col, anova.statistic, anova.pvalue))\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao calcular ANOVA para {col}: {e}\")\n",
    "\n",
    "df_anova = pd.DataFrame(anova_results, columns=['Variável Categórica', 'F-statistic', 'p-value'])\n",
    "\n",
    "df_anova.sort_values(by='p-value', ascending=True, inplace=True)\n",
    "\n",
    "top_10_correlations = df_anova.head(10)\n",
    "\n",
    "print(\"As 10 maiores correlações:\")\n",
    "print(top_10_correlations)\n",
    "\n",
    "bottom_10_correlations = df_anova.tail(10)\n",
    "\n",
    "print(\"\\nAs 10 menores correlações:\")\n",
    "print(bottom_10_correlations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 20))\n",
    "sns.heatmap(treino[num_cols].corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_palette = 'viridis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "sns.barplot(x='Neighborhood', y='SalePrice', data=treino, palette='coolwarm', errorbar=None)\n",
    "plt.title('SalePrice por Neighbourhood')\n",
    "plt.xlabel('Neighbourhood')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='OverallQual', y='SalePrice', data=treino, palette='YlOrBr', errorbar=None)\n",
    "plt.title('SalePrice por OverallQual')\n",
    "plt.xlabel('OverallQual')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='GrLivArea', y='SalePrice', data=treino, alpha=0.7 , hue='SalePrice', palette=s_palette)\n",
    "plt.title('SalePrice por GrLivArea')\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='GarageCars', y='SalePrice', data=treino, palette='Blues', errorbar=None)\n",
    "plt.title('SalePrice por GarageCars')\n",
    "plt.xlabel('GarageCars')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='GarageArea', y='SalePrice', data=treino, color='blue')\n",
    "plt.title('SalePrice por GarageArea (Line Plot)')\n",
    "plt.xlabel('GarageArea')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(x='TotalBsmtSF', y='SalePrice', data=treino, color='blue')\n",
    "plt.title('SalePrice por TotalBsmtBF')\n",
    "plt.xlabel('TotalBsmtBF')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='1stFlrSF', y='SalePrice', data=treino, alpha=0.7 , hue='SalePrice', palette=s_palette)\n",
    "plt.title('SalePrice por 1stFlrSF')\n",
    "plt.xlabel('1stFlrSF')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='FullBath', y='SalePrice', data=treino, palette='magma', errorbar=None)\n",
    "plt.title('SalePrice por FullBath')\n",
    "plt.xlabel('FullBath')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='TotRmsAbvGrd', y='SalePrice', data=treino, palette='Spectral', errorbar=None)\n",
    "plt.title('SalePrice por TotRmsAbvGrd')\n",
    "plt.xlabel('TotRmsAbvGrd')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='YearBuilt', y='SalePrice', data=treino, alpha=0.7, hue='SalePrice', palette=s_palette)\n",
    "plt.title('SalePrice por YearBuilt')\n",
    "plt.xlabel('YearBuilt')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend().remove()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='YearRemodAdd', y='SalePrice', data=treino, alpha=0.7 , hue='SalePrice', palette=s_palette)\n",
    "plt.title('SalePrice por YearRemodAdd')\n",
    "plt.xlabel('YearRemodAdd')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend().remove()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cat_cols = [\n",
    "    'ExterQual', 'KitchenQual', 'Foundation', \n",
    "    'SaleCondition', 'SaleType', 'MSZoning', 'HouseStyle', \n",
    "    'LotShape', 'CentralAir'\n",
    "]\n",
    "\n",
    "filtered_data = treino[top_cat_cols + ['SalePrice']]\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, feature in enumerate(top_cat_cols, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.barplot(x=feature, y='SalePrice', data=filtered_data, palette='mako', errorbar=None)\n",
    "    plt.title(f'SalePrice por {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('SalePrice')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_prices = treino.groupby('Neighborhood')['SalePrice'].mean().sort_values(ascending=False)\n",
    "\n",
    "top_neighborhoods = neighborhood_prices.head(5).index.tolist()\n",
    "print(\"Bairros com maior preço médio:\")\n",
    "print(top_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = treino[treino['Neighborhood'].isin(top_neighborhoods)]\n",
    "\n",
    "variables_of_interest = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF',\n",
    "    '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd' ,\n",
    "    'ExterQual', 'KitchenQual', 'Foundation', 'HeatingQC', 'SaleCondition'\n",
    "]\n",
    "\n",
    "num_plots = len(variables_of_interest)\n",
    "rows = (num_plots // 4) + 1\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, feature in enumerate(variables_of_interest, 1):\n",
    "    plt.subplot(rows, 4, i)\n",
    "    if treino[feature].dtype == 'object':  \n",
    "        sns.histplot(filtered_data[feature], bins=20, kde=True, stat='density')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Contagem')\n",
    "    else:\n",
    "        sns.histplot(filtered_data[feature], bins=20, kde=True, stat='density')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Densidade')\n",
    "    plt.title(f'{feature} - Bairros com Maior Preço Médio')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhood_prices = treino.groupby('Neighborhood')['SalePrice'].mean().sort_values(ascending=True)\n",
    "\n",
    "bottom_neighborhoods = neighborhood_prices.head(5).index.tolist()\n",
    "print(\"Bairros com menor preço médio:\")\n",
    "print(bottom_neighborhoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = treino[treino['Neighborhood'].isin(bottom_neighborhoods)]\n",
    "\n",
    "variables_of_interest = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF',\n",
    "    '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd',\n",
    "    'ExterQual', 'KitchenQual', 'Foundation', 'HeatingQC', 'SaleCondition'\n",
    "]\n",
    "\n",
    "num_plots = len(variables_of_interest)\n",
    "rows = (num_plots // 4) + 1\n",
    "\n",
    "plt.figure(figsize=(18, 12))\n",
    "for i, feature in enumerate(variables_of_interest, 1):\n",
    "    plt.subplot(rows, 4, i)\n",
    "    if treino[feature].dtype == 'object':  \n",
    "        sns.histplot(filtered_data[feature], bins=20, kde=True, stat='density')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Média de SalePrice')\n",
    "    else:\n",
    "        sns.histplot(filtered_data[feature], bins=20, kde=True, stat='density')\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel('Densidade')\n",
    "    plt.title(f'{feature} - Bairros com Menor Preço Médio')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapiro_results = {}\n",
    "for col in num_cols:\n",
    "    data = treino[col].dropna() \n",
    "    stat, p_value = shapiro(data)\n",
    "    shapiro_results[col] = {'Estatística': stat, 'Valor p': p_value}\n",
    "\n",
    "for col, result in shapiro_results.items():\n",
    "    print(f\"\\nTeste de Shapiro-Wilk para '{col}':\")\n",
    "    print(f\"  Estatística: {result['Estatística']}\")\n",
    "    print(f\"  Valor p: {result['Valor p']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levene_results = {}\n",
    "\n",
    "for col in num_cols:\n",
    "    stat, p_value = levene(treino[col].dropna(), treino['SalePrice'].dropna())\n",
    "    levene_results[col] = {'Estatística': stat, 'Valor p': p_value}\n",
    "\n",
    "for col, result in levene_results.items():\n",
    "    print(f\"\\nTeste de Levene para '{col}':\")\n",
    "    print(f\"  Estatística: {result['Estatística']}\")\n",
    "    print(f\"  Valor p: {result['Valor p']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_indicatores_num = treino[num_cols].isnull().astype(int)\n",
    "null_indicatores_num['SalePrice'] = treino['SalePrice']\n",
    "\n",
    "null_correlacao = null_indicatores_num.corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "maiores_corr_numer = null_correlacao.head(10) \n",
    "menores_corr_numer = null_correlacao.tail(10)\n",
    "\n",
    "print(\"Top 10 maiores correlações entre valores nulos e SalePrice:\\n\", maiores_corr_numer)\n",
    "print(\"\\nTop 10 menores correlações entre valores nulos e SalePrice:\\n\", menores_corr_numer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "maiores_corr_numer[1:].plot(kind='bar', color='green')\n",
    "plt.title('Top 10 maiores correlações entre valores nulos (numéricas) e SalePrice')\n",
    "plt.ylabel('Correlação')\n",
    "plt.xlabel('Colunas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_indicatores_cat = treino[cat_cols].isnull().astype(int)\n",
    "null_indicatores_cat['SalePrice'] = treino['SalePrice']\n",
    "\n",
    "null_correlacao_cat = null_indicatores_cat.corr()['SalePrice'].sort_values(ascending=False)\n",
    "\n",
    "maiores_corr_cat = null_correlacao_cat.head(20)\n",
    "menores_corr_cat = null_correlacao_cat.tail(10)\n",
    "\n",
    "print(\"Maiores correlações entre valores nulos (categóricas) e SalePrice:\\n\", maiores_corr_cat)\n",
    "print(\"\\nMenores correlações entre valores nulos (categóricas) e SalePrice:\\n\", menores_corr_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "maiores_corr_cat[1:].plot(kind='bar', color='blue')\n",
    "plt.title('Top 10 maiores correlações entre valores nulos (categóricas) e SalePrice')\n",
    "plt.ylabel('Correlação')\n",
    "plt.xlabel('Colunas')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis numéricas\n",
    "numeric_cols_with_missing = treino[num_cols].columns[treino[num_cols].isnull().any()]\n",
    "for col in numeric_cols_with_missing:\n",
    "    treino[col].fillna(treino[col].median(), inplace=True)\n",
    "\n",
    "# Variáveis categóricas\n",
    "categorical_cols_with_missing = treino[cat_cols].columns[treino[cat_cols].isnull().any()]\n",
    "for col in categorical_cols_with_missing:\n",
    "    treino[col].fillna(treino[col].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', \n",
    "    'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', \n",
    "    'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', \n",
    "    'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', \n",
    "    'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', \n",
    "    'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n",
    "    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', \n",
    "    'MoSold', 'YrSold'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', \n",
    "    'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', \n",
    "    'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n",
    "    'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', \n",
    "    'MasVnrType', 'Foundation', 'BsmtQual', 'BsmtCond', \n",
    "    'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', \n",
    "    'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', \n",
    "    'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "    'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', \n",
    "    'MiscFeature', 'SaleType', 'SaleCondition'\n",
    "]\n",
    "\n",
    "le = OrdinalEncoder()\n",
    "for column in categorical_features:\n",
    "    treino[f\"{column}_le\"] = le.fit_transform(treino[column].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "treino[num_cols] = scaler.fit_transform(treino[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleção de features numéricas com alta correlação\n",
    "num_features = [\n",
    "    'OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', \n",
    "    'TotalBsmtSF', '1stFlrSF', 'FullBath', 'TotRmsAbvGrd', \n",
    "    'YearBuilt', 'YearRemodAdd'\n",
    "]\n",
    "\n",
    "# Seleção de features categóricas com alta correlação\n",
    "cat_features = [\n",
    "    'Neighborhood', 'ExterQual', 'KitchenQual', 'Foundation', \n",
    "    'SaleCondition', 'SaleType', 'MSZoning', 'HouseStyle', \n",
    "    'LotShape', 'CentralAir'\n",
    "]\n",
    "\n",
    "# Combinar features numéricas e categóricas\n",
    "selected_features = num_features + cat_features\n",
    "X = treino[selected_features]\n",
    "y = treino['SalePrice']\n",
    "\n",
    "# Pré-processamento para dados numéricos: imputação de valores ausentes e normalização\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pré-processamento para dados categóricos: imputação de valores ausentes e codificação one-hot\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar etapas de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "# Criar um pipeline que inclui pré-processamento e o modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar o modelo\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar o modelo\n",
    "y_pred = pipeline.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation score\n",
    "cv_score = cross_val_score(pipeline, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-cv_score)\n",
    "print(\"Cross-validated RMSE:\", cv_rmse.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as features\n",
    "num_features = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF']\n",
    "cat_features = ['Neighborhood', 'ExterQual', 'KitchenQual', 'Foundation', 'SaleCondition']\n",
    "\n",
    "X = treino[num_features + cat_features]\n",
    "y = treino['SalePrice']\n",
    "\n",
    "# Pré-processamento para dados numéricos: imputação de valores ausentes e normalização\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pré-processamento para dados categóricos: imputação de valores ausentes e codificação one-hot\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinar etapas de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "# Criar um pipeline que inclui pré-processamento e o modelo de regressão linear Multipla\n",
    "pipeline_reg = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline_reg.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred_reg = pipeline_reg.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "mse_reg = mean_squared_error(y_test, y_pred_reg)\n",
    "rmse_reg = np.sqrt(mse_reg)\n",
    "print(f\"Mean Squared Error (Regressão Linear): {mse_reg:.4f}\")\n",
    "print(f\"Root Mean Squared Error (Regressão Linear): {rmse_reg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo um limiar para determinar se o preço de venda é alto ou baixo\n",
    "threshold = np.percentile(treino['SalePrice'], 75)  # preço acima do 75º percentil é considerado alto\n",
    "\n",
    "# Criando a variável binária de saída\n",
    "treino['SalePrice_bin'] = treino['SalePrice'].apply(lambda x: 1 if x >= threshold else 0)\n",
    "\n",
    "# Verificando o balanceamento das classes\n",
    "print(treino['SalePrice_bin'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar as mesmas features usadas na regressão linear\n",
    "X = treino[num_features + cat_features]\n",
    "y_bin = treino['SalePrice_bin']\n",
    "\n",
    "# Combinar etapas de pré-processamento\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_features),\n",
    "        ('cat', cat_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "# Criar um pipeline que inclui pré-processamento e o modelo de classificação (Logistic Regression)\n",
    "pipeline_clf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=42)\n",
    "\n",
    "# Treinar o modelo\n",
    "pipeline_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazer previsões\n",
    "y_pred_clf = pipeline_clf.predict(X_test)\n",
    "\n",
    "# Avaliar o desempenho do modelo\n",
    "accuracy = accuracy_score(y_test, y_pred_clf)\n",
    "print(f\"Acurácia do modelo de classificação: {accuracy:.2f}\")\n",
    "\n",
    "# Mostrar relatório de classificação\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred_clf))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
